import whisper
import os
import datetime

# ============ é…ç½® =============
video_path = r"C:\Users\15259\Videos\pijiu.wav"  # è§†é¢‘æ–‡ä»¶è·¯å¾„
output_srt_path = r"C:\Users\15259\Videos\888å•¤é…’èŠ‚.srt"  # è¾“å‡ºçš„å­—å¹•è·¯å¾„
model_size = "small"  # å¯é€‰ tiny / base / small / medium / large
language = None  # è®¾ç½®ä¸º None è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
# ===============================

# å·¥å…·å‡½æ•°ï¼šå°†ç§’è½¬ä¸º SRT æ—¶é—´æˆ³æ ¼å¼
def format_timestamp(seconds: float):
    td = datetime.timedelta(seconds=round(seconds, 3))
    total_seconds = int(td.total_seconds())
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = int((td.total_seconds() - total_seconds) * 1000)
    return f"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}"

# åŠ è½½æ¨¡å‹
print(f"ğŸ” æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ ({model_size}) ...")
model = whisper.load_model(model_size)
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆã€‚")

# å¼€å§‹è½¬å½•
print(f"ğŸ§ å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼š{video_path}")
result = model.transcribe(video_path, language=language)
print("âœ… è½¬å½•å®Œæˆã€‚æ­£åœ¨ç”Ÿæˆå­—å¹•æ–‡ä»¶...")

# å†™å…¥ .srt å­—å¹•æ–‡ä»¶
with open(output_srt_path, "w", encoding="utf-8") as f:
    for i, segment in enumerate(result["segments"]):
        start = format_timestamp(segment["start"])
        end = format_timestamp(segment["end"])
        text = segment["text"].strip()
        f.write(f"{i+1}\n{start} --> {end}\n{text}\n\n")

print(f"âœ… å­—å¹•æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{output_srt_path}")
